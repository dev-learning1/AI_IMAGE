{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8129fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef31dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding='same' : 텐서플로우가 자동으로 패딩을 삽입해 입력값과 출력값의 크기를 맞춰줌\n",
    "# padding='valid' : 텐서플로우가 자동으로 패딩을 적용하지 않고 필터를 적용해서 출력값의 크기가 작이짐\n",
    " \n",
    "def get_sequential_model(input_shape):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Input(input_shape),\n",
    "            \n",
    "            # 1st\n",
    "            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),    # 64 : 필터 수(출력), 3 : 3x3 필터 크기 => 각 필터의 가중치는 다름\n",
    "            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
    "            layers.MaxPool2D(),\n",
    "            layers.BatchNormalization(),    # 배치별 특징 값을 정규화(relu로 인한 다양한 값 생성(local optimal)) => 학습 속도 증가\n",
    "            layers.Dropout(0.5),\n",
    "            \n",
    "            # 2nd\n",
    "            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),    # 128 : 필터 수(출력), 3 : 3x3 필터 크기 => 각 필터의 가중치는 다름\n",
    "            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n",
    "            layers.MaxPool2D(),\n",
    "            layers.BatchNormalization(),    # 배치별 특징 값을 정규화(relu로 인한 다양한 값 생성(local optimal)) => 학습 속도 증가\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            # FC\n",
    "            layers.GlobalMaxPool2D(),\n",
    "            layers.Dense(128, activation='relu'),    # 2nd에서 출력이 128개\n",
    "            layers.Dense(1, activation='sigmoid')    # 마지막 결과 : 맞는지 여부(2진 논리)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8678f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "model = get_sequential_model(input_shape)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27fdb519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, csv_path, fold, image_size, mode='train',  shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "            \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    # sample() : 전체 row에서 몇 %의 데이터를 return 할 것인지 설정\n",
    "    # frac : 데이터프레임으로 부터 특정 비율로 무작위 표본 추출을 하고 싶으면 0~1 사이의 부동소수점 입력\n",
    "    # reset_index() : drop=True 옵션을 설정하면 인덱스 열을 보통의 자료열로 설정하는 것이 아니라 버림\n",
    "    # 여기서 인데스 열이란 데이터프레임 맨 앞 열에 생성되는 인덱스 열을 말함\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "    # len() 함수를 재구현  (공유파일 첫 달에서 스페셜매소드 파일에서 다뤘음)\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.df) / self.batch_size)\n",
    "    \n",
    "    # 배열을 쓸 때 자동으로 불러지는 것\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = (idx + 1) * self.batch_size\n",
    "        data = self.df.iloc[start:end]\n",
    "        batch_x, batch_y = self.get_data(data)\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "        \n",
    "    def get_data(self, data):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        \n",
    "        # iterrows\n",
    "        # 데이터프레임에서 row의 개수만큼 반복\n",
    "        # 튜플로 리턴[index, 행정보(Series)]\n",
    "        for _, r in data.iterrows():             \n",
    "            file_name = r['file_name']\n",
    "            image = cv2.imread(f'D:/data_ai/5_AI/images/{file_name}.jpg')\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "            image = image / 255    # 정규화\n",
    "            \n",
    "            label = int(r['species']) - 1    # 밑에서 class_name 인덱스와 맞추기위해 (-1)해줌\n",
    "            \n",
    "            batch_x.append(image)\n",
    "            batch_y.append(label)\n",
    "            \n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56e98ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'D:/data_ai/5_AI/kfolds.csv'\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    # 옵션\n",
    "    batch_size = 128, \n",
    "    csv_path = csv_path, \n",
    "    fold = 1, \n",
    "    image_size = 256, \n",
    "    mode = 'train', \n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "valid_generator = DataGenerator(\n",
    "    # 옵션\n",
    "    batch_size = 128, \n",
    "    csv_path = csv_path, \n",
    "    fold = 1, \n",
    "    image_size = 256, \n",
    "    mode = 'val', \n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f1d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping : Epoch을 많이 돌린 후 특정 시점에 멈추게 함\n",
    "# monitor : EarlyStopping의 기준이 되는 값. 예) val_loss 더 이상 감소되지 않을 경우 EarlyStopping 적용\n",
    "# patience : Trainning이 진행됨에도 더 이상 monitor되는 값의 개선이 없을 경우 몇 번 epoch을 진행할 지 설정\n",
    "# mode : monitor되는 값이 최소가 돼야 하는지, 최대가 돼야 하는지 설정\n",
    "# restore_best_weights : true라면 trainning이 끝난 후, model의 weight를 monitor하고 있던 값이 가장 좋았을 경우의 weight로 복원,\n",
    "# false라면 마지막 trainning이 끝난 후의 weight로 설정\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=3, mode='min', restore_best_weights=False\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c1d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce_on_plateau : 모델의 개선이 없을 경우 learning rate를 조절해 모델의 개선을 유도함\n",
    "# monitor : reduce_on_plateau의 기준이 되는 값. 예) val_loss 더 이상 감소되지 않을 경우 reduce_on_plateau 적용\n",
    "# factor : learning rate를 얼마나 감쇠킬지 정하는 값. 새로운 learning rate는 기존 learning rate * factor\n",
    "# patience : trainning이 진해됨에도 더 이상 monitor되는 값의 개선이 없을 경우 최적의 monitor 값을 기준으로\n",
    "# 몇 번의 epoch을 진행하고 learning rate를 조절할지의 값을 설정\n",
    "# verbose : 세세한 출력 방법. learning rate하는 것이 콘솔에 출력\n",
    "\n",
    "reduce_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min', min_lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a3ba4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoint : 모델의 경로 설정\n",
    "# 모델 경로를 '{epoch:02d}-{val_losee:.2f}.hdf5'라고 하면 앞의 명시한 문자열로 파일을 저장\n",
    "# 예) 01-0.12.h5\n",
    "# save_weights_only : True(weight만 저장), False(모델, layer, weight 모두 저장)\n",
    "# save_best_only : True(모델의 정확도가 최고값을 갱신했을 때만 저장), False(매회 저장)\n",
    "\n",
    "filepath = '{epoch:02d}-{val_losee:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b4c756",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\heejeong\\AppData\\Local\\Temp\\ipykernel_8608\\1353968809.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     callbacks=[\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data = valid_generator,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        reduce_on_plateau,\n",
    "        model_checkpoint\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 만족할 만한 결과 안나옴(60~70%)\n",
    "# sequential이 cnn에 적합하지 않음\n",
    "# 보족한 자료 + 데이터 추가 못함 => 기존의 자료를 뿔려야함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
